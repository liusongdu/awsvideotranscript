WEBVTT FILE

1
00:00:00.000 --> 00:00:07.000
so a few weeks back a colleague of mine
on the EBS team told me a story about
when he first moved to Seattle now he

2
00:00:07.000 --> 00:00:12.000
decided that he wanted to get a bike to
commute to and from work and for those
of you that have never visited seattle

3
00:00:12.000 --> 00:00:21.000
seattle has some hills and those hills
make San Francisco streets look tame so
anyway he buys his bike and he tries to

4
00:00:21.000 --> 00:00:29.000
commute home unfortunately he doesn't
even make it all the way home he has to
get off his bike and walk come to find

5
00:00:29.000 --> 00:00:36.000
out he's only ever ridden a single speed
bike and he didn't realize how to use
the gears on his new bike once he

6
00:00:36.000 --> 00:00:44.000
figured out the gears he was able to
climb hills I'm mark and I'm a software
engineer on the EBS team and I've been

7
00:00:44.000 --> 00:00:51.000
focusing on the core io path with EBS
for the last four years now my goal
today is that by the end of the talk

8
00:00:51.000 --> 00:01:00.000
you'll know a few more tips and tricks
that will help you improve the
performance of your perform much like my

9
00:01:00.000 --> 00:01:11.000
colleague learn how to use his bike so
how many people are returning after
doubles talk good number of people and

10
00:01:11.000 --> 00:01:17.000
some new faces that's great so for those
of you that are just joining I'm going
to spend a few minutes to recap what

11
00:01:17.000 --> 00:01:27.000
Google just talked about and go over an
overview of what EBS is so Amazon EBS is
block storage for ec2 now we look like a

12
00:01:27.000 --> 00:01:37.000
block device to your instance but it's
important to remember that EBS is not
just a bunch of disks so what is e BS

13
00:01:37.000 --> 00:01:45.000
BBs is persistent network block storage
as a service now the service part that's
really cool it means that we can iterate

14
00:01:45.000 --> 00:01:55.000
and improve the performance and improves
the feature set on EBS without you
having to do anything now EBS is also a

15
00:01:55.000 --> 00:02:01.000
zonal service and that means that once
your volume is created all of the
resources for your volume live within a

16
00:02:01.000 --> 00:02:10.000
single availability zone and that volume
can be attached to any instance in that
availability zone so EBS has other

17
00:02:10.000 --> 00:02:15.000
features such as snapshots and
encryption
designed for five nines of availability

18
00:02:15.000 --> 00:02:29.000
and we create over two million volumes
every day EBS has a few different volume
types EBS magnetic which is the original

19
00:02:29.000 --> 00:02:37.000
volume type and to SSD back volume types
general-purpose volumes or gp2 and
provision i have signs which we refer to

20
00:02:37.000 --> 00:02:50.000
as P I ops so EBS magnetic volumes these
are best for in frequently accessed data
so say you take a snapshot of your

21
00:02:50.000 --> 00:02:57.000
database you can you can stuff the
snapshot on the magnetic drive so that
it's next to your instance in case you

22
00:02:57.000 --> 00:03:05.000
need it quickly it's also good for log
storage so application logs and system
logs and other things like that and if

23
00:03:05.000 --> 00:03:12.000
you have cost sensitive workloads
magnetics still a good choice for you
now gp2 volumes I'm not going to go

24
00:03:12.000 --> 00:03:19.000
through all of the slides that Dougal
did to explain gp2 volumes but the
bottom line with GP two volumes is that

25
00:03:19.000 --> 00:03:29.000
they just work we've designed these to
be applicable to most workloads and they
have an eye ops base line that's up to

26
00:03:29.000 --> 00:03:38.000
ten thousand gigabytes and that is
allocated based on the size of your
volume GP two volumes also for smaller

27
00:03:38.000 --> 00:03:46.000
volumes have a burst bucket in this
burst bucket allows you to to drive
3,000 I ops for up to 30 minutes and now

28
00:03:46.000 --> 00:03:53.000
when you're not driving that 3,000 I ops
that bucket continuously refills at your
baseline rate so it's a little confusing

29
00:03:53.000 --> 00:04:01.000
with the with the burst bucket but
really I don't want you to have to think
about that these just work and in fact

30
00:04:01.000 --> 00:04:10.000
they work so well that most of our GP
two volumes don't even come close to
exhausting their burst bucket

31
00:04:10.000 --> 00:04:18.000
now for your mission critical workloads
those are your critical production
database that can't even tolerate a

32
00:04:18.000 --> 00:04:28.000
stall on an honest select things like
that recommend provision I Absalom's now
these can be provisioned up to 20,000 I

33
00:04:28.000 --> 00:04:35.000
ops and that those I ops are independent
of the size of the volume these also
have a higher throughput and a higher

34
00:04:35.000 --> 00:04:48.000
performance consistency so now let's
jump into why you're all here but before
we get started let's talk about a little

35
00:04:48.000 --> 00:04:58.000
theory so John little is a professor and
he spent most of his research focusing
on operations and in the 50s and 60s he

36
00:04:58.000 --> 00:05:09.000
was thinking about EBS wait that's a lie
he was thinking about a bank it turns
out that his research then was actually

37
00:05:09.000 --> 00:05:18.000
still applicable to EBS and he proposed
a theorem and that theorem seems obvious
now that it's on paper but nobody had

38
00:05:18.000 --> 00:05:25.000
really thought about it and it's that
the wait time of a request in his case
the patrons waiting to do transactions

39
00:05:25.000 --> 00:05:34.000
is equal to the queue length divided by
the arrival rate and so this is exactly
how EBS works and this is exactly how

40
00:05:34.000 --> 00:05:41.000
most systems work now it's also
important to note that these three
values as they pertain to EBS are

41
00:05:41.000 --> 00:05:51.000
available as cloud watch metrics and
we'll talk a little bit more about that
later

42
00:05:51.000 --> 00:05:58.000
so when we talk about performance
optimization we look at these three
things there are a few other things but

43
00:05:58.000 --> 00:06:06.000
these are the core things that we think
about the I ops are the rate of i/o that
is going to your volume the latency

44
00:06:06.000 --> 00:06:11.000
which is the time that those I ops take
to complete and the throughput now your
database workloads are going to be

45
00:06:11.000 --> 00:06:20.000
focused mainly on I ops and latency your
streaming video streaming log processing
splunk kafka things like that are more

46
00:06:20.000 --> 00:06:29.000
concerned about throughput workloads so
to achieve end end performance
optimization you need to look at these

47
00:06:29.000 --> 00:06:36.000
four components for many of you this is
going to be review but let's make sure
everybody's on the same page you have

48
00:06:36.000 --> 00:06:44.000
your ec2 instance that's where your
application is running your application
is submitting I oh and that IO is

49
00:06:44.000 --> 00:06:52.000
targeted at an EBS volume to get to that
EBS volume there needs to be a network
link in play and these four key

50
00:06:52.000 --> 00:07:05.000
components work together so to maximize
performance it's important to arrange
them into a balanced system let's start

51
00:07:05.000 --> 00:07:13.000
by looking at the i/o component all
right I'll admit I'm a little bit of a
scuba diver so I used a dive slide

52
00:07:13.000 --> 00:07:20.000
because we're going to go on a deep dive
into the kernel now a lot of you have
focused on storage optimization but your

53
00:07:20.000 --> 00:07:29.000
focus has been on on-premise systems
getting an i/o to the storage layer in a
virtualized system is a little bit

54
00:07:29.000 --> 00:07:38.000
different and so I thought it would be
important to take some time to explain
how that happens so you have your

55
00:07:38.000 --> 00:07:45.000
instance your instance is running an
application your application wants to do
an i/o that could be a reader right

56
00:07:45.000 --> 00:07:52.000
could be written in Java assembly
doesn't matter eventually that read gets
converted into a system pollen to the

57
00:07:52.000 --> 00:08:00.000
colonel within your instance along with
that system call is a buffer and that
buffer is where the data goes now if

58
00:08:00.000 --> 00:08:05.000
it's a read the EBS volume will put the
data there if it's a right that's the
data that's going to

59
00:08:05.000 --> 00:08:12.000
get recorded on your abs volume and so
the colonel knows that it's not talking
to a real block device underneath it's

60
00:08:12.000 --> 00:08:24.000
talking to virtualize storage and so it
contacts an IO domain now forever ec2
instance it has a communication path

61
00:08:24.000 --> 00:08:31.000
with an IO domain and that IO domain has
all the software that directly accesses
the EBS volume the problem is that I Oh

62
00:08:31.000 --> 00:08:40.000
domain doesn't have access to your
instances memory and so the instance has
to alert the IO domain and say I'm going

63
00:08:40.000 --> 00:08:50.000
to grant you permission to this piece of
memory and that process is called a
grant mapping and now this process is

64
00:08:50.000 --> 00:08:59.000
actually really fast and pretty neat
it's fast for bulk data transfers but it
can be a little bit Causton costly from

65
00:08:59.000 --> 00:09:06.000
a CPU perspective because every time you
do one of these it requires at least one
TLB flush as we switch back and forth

66
00:09:06.000 --> 00:09:21.000
between the guest instance your your ec2
instance and the i/o domain so once
we've got that IO mapped now your

67
00:09:21.000 --> 00:09:27.000
instance is able to create a request and
that request looks a little bit
differently a little bit different from

68
00:09:27.000 --> 00:09:36.000
a normal block i/o request but really
it's about the same it has the location
that you want to read from or right from

69
00:09:36.000 --> 00:09:47.000
the amount of data that you want to read
and a bunch 11 to be more specific slots
for these grant mappings now that

70
00:09:47.000 --> 00:09:53.000
instance communicates with the i/o
domain for these requests through a
single memory page that is mapped and

71
00:09:53.000 --> 00:010:04.000
that your instance an i/o domain have
access to its treated as a circular q a
ring buffer and bring buffers as some of

72
00:10:04.000 --> 00:10:10.000
you probably are familiar with our most
efficient when every request is the same
size and so you're probably thinking why

73
00:10:10.000 --> 00:10:17.000
only 11 grant references well it turns
out that if we had a 12th grant
reference in there we

74
00:10:17.000 --> 00:10:24.000
can't fit 32 iOS into the queue and we
want that cue to be base 2 and we want
to have enough a large enough cue that

75
00:10:24.000 --> 00:10:35.000
you can submit enough of Io the problem
is this only is just under a meg and a
half of data so it's not a whole lot of

76
00:10:35.000 --> 00:10:46.000
data that can be outstanding and if
you're submitting larger iOS they'll get
split down into 44k so the 398 colonel

77
00:10:46.000 --> 00:10:58.000
in linux included a number of features
and so if you remember I was talking
about the TLB flushes before if you're

78
00:10:58.000 --> 00:11:05.000
trying to do a lot of i/o your instance
is going to try and submit an i/o we
have to do a TLB flush io domain has to

79
00:11:05.000 --> 00:11:10.000
do that grant mapping may do a TLB flush
on the way out and then when the Iowas
done we'll have to repeat the process

80
00:11:10.000 --> 00:11:17.000
again and so the CPU is doing a lot of
extra work it turns out in computer
science especially that when you

81
00:11:17.000 --> 00:11:24.000
question your assumptions oftentimes you
end up with something even better and
what the Linux kernel engineers realized

82
00:11:24.000 --> 00:11:33.000
is that modern CPUs are really good at
copying memory particularly memory
that's been recently accessed and so

83
00:11:33.000 --> 00:11:41.000
what they did is wrote in some
capabilities that allow your instance
and the i/o domain to pre establish a

84
00:11:41.000 --> 00:11:47.000
pool of memory that they both have
access to all the time and that's
established when the volume is attached

85
00:11:47.000 --> 00:11:54.000
to your instance when your instance
wants to do an i/o now all it does is
treats that pool of memory as a bounce

86
00:11:54.000 --> 00:12:00.000
buffer and actually copies the memory
back and forth and the amazing thing
about this is we've seen significant

87
00:12:00.000 --> 00:12:07.000
both I ops and latency improvements
depending on the instance type and the
the volumes that are going underneath it

88
00:12:07.000 --> 00:12:14.000
almost double when using this method as
opposed to doing TLB flushes for every
other or for every single eye out

89
00:12:14.000 --> 00:12:25.000
another feature that's in the three day
colonel is the concept of indirect
grants so instead of putting each grant

90
00:12:25.000 --> 00:12:33.000
that makes up that IO into the read
request what happens now
is you can put those grants into one of

91
00:12:33.000 --> 00:12:40.000
those pages and then just include a
reference in that request to that page
so your i/o request can be significantly

92
00:12:40.000 --> 00:12:49.000
larger now by default we still allow 32
requests and those requests are 128 k
maximum and what we found is that that's

93
00:12:49.000 --> 00:13:01.000
a good balance between the amount of
memory required and the actual
performance benefits so let's come back

94
00:13:01.000 --> 00:13:08.000
up a little bit stop for a moment do a
safety stop make sure we've shucking out
the cobwebs for those of you that got a

95
00:13:08.000 --> 00:13:15.000
little confused I'm going to show you a
smaller example of indirect references
so this is before the 38 colonel if you

96
00:13:15.000 --> 00:13:27.000
want to submit 128 k io that gets broken
up into three requests a 44 k 244 k's of
40k now if you notice that last request

97
00:13:27.000 --> 00:13:34.000
is not a full request so we're actually
able to put even less data into the
queue and those three requests each take

98
00:13:34.000 --> 00:13:40.000
up a slot in the queue now I'm a
computer scientist so I start counting
at zero but there's 32 slots here I

99
00:13:40.000 --> 00:13:51.000
promise we only have the ability to put
nine of these 128 k requests into the
queue with indirect references same 128

100
00:13:51.000 --> 00:14:04.000
k io just takes up a single slot so a
tip ensure you're using a kernel version
that's greater than 38 now fortunately

101
00:14:04.000 --> 00:14:15.000
every version of Amazon Linux since 2003
or 2013 09 has these features enabled
abantu 1404 rel 7 and that also carries

102
00:14:15.000 --> 00:14:21.000
over to CentOS 7 also have these
features enabled now you don't have to
be using one of these amies one of these

103
00:14:21.000 --> 00:14:28.000
distributions as long as you've got the
three-date kernel or better running in
your instance you'll get the benefits of

104
00:14:28.000 --> 00:14:40.000
this
so as it relates to EBS queue depth is
the pending IO in flight you need to

105
00:14:40.000 --> 00:14:48.000
have I 0 and Q in order for it to be
processed by EBS so you need to keep the
ABS volume busy at all times now there's

106
00:14:48.000 --> 00:14:56.000
no perfect cued up sometimes it'll be
dependent upon your application but if
you're getting the latency that you're

107
00:14:56.000 --> 00:15:04.000
expecting you're probably driving enough
queue depth and what you need to
understand is that once you have what

108
00:15:04.000 --> 00:15:09.000
you expect you don't need to worry about
this and if you're some workloads this
is a tunable and I'll demonstrate that a

109
00:15:09.000 --> 00:15:15.000
little bit later but the important
takeaway here is that we have to have
something in the queue for EBS to

110
00:15:15.000 --> 00:15:25.000
process it now types of iOS that we have
this is a big long chart I don't expect
you to memorize it but it's just kind of

111
00:15:25.000 --> 00:15:31.000
a sample of the different types of
workloads that run on an AWS most of
your database workloads are listed at

112
00:15:31.000 --> 00:15:38.000
the top and they do smaller random iOS
so they're more concerned about I ops
I've thrown gluster on the bottom I ran

113
00:15:38.000 --> 00:15:45.000
out of room but Kafka and other things
like that are larger sequential
workloads and they're looking more at

114
00:15:45.000 --> 00:15:57.000
throughput so our customers run a very
diverse set of workloads from e-commerce
websites storing customer metadata

115
00:15:57.000 --> 00:16:06.000
perhaps for your video game or whatever
your ecommerce site some big data log
analysis things like that to simplify

116
00:16:06.000 --> 00:16:13.000
the rest of this talk I'm going to use
benchmarks and I'm specifically choosing
one that represents transactional

117
00:16:13.000 --> 00:16:19.000
workloads i'll be using a tool called
sis bench some of you are probably
familiar with that with my sequel is the

118
00:16:19.000 --> 00:16:27.000
underlying database now the choices are
just random I picked ones that I was
comfortable with but these tips that i'm

119
00:16:27.000 --> 00:16:36.000
about to share will apply to any in them
now benchmarks are great for course
tuning they're great for showing

120
00:16:36.000 --> 00:16:43.000
differences between different volume
types and things like that but really to
get the best feel for how your workloads

121
00:16:43.000 --> 00:16:54.000
going to perform on an EBS volume you
need to use your real world production
workload so I've picked a surprisingly

122
00:16:54.000 --> 00:17:03.000
common instance type in configuration to
start our journey today and I picked an
m24 extra large instance i attached a

123
00:17:03.000 --> 00:17:13.000
500 gig EBS magnetic volume and then I
run the bench workload a few different
times and so to show how increasing cute

124
00:17:13.000 --> 00:17:18.000
apps can change the number of
transactions your database can do iran
that suspends workload a few times

125
00:17:18.000 --> 00:17:25.000
increasing the number of my sequel
threads which is really increasing the
queue depth to the database now I don't

126
00:17:25.000 --> 00:17:32.000
really want to focus on specifics that
may not be relevant to your particular
application but what really matters is

127
00:17:32.000 --> 00:17:39.000
the relative performance here and so I
removed the values on the x and y axis
but I do want to call out a few things

128
00:17:39.000 --> 00:17:49.000
this graph is linear on the y-axis
starting at 0 so it's a normal graph I
didn't play any tricks with log scale or

129
00:17:49.000 --> 00:17:56.000
skipping lines or anything like that and
then the x-axis I started with two
threads and then I increased it to some

130
00:17:56.000 --> 00:18:04.000
number and so what you'll notice is that
as you're going through this that as you
increase the number of threads that are

131
00:18:04.000 --> 00:18:12.000
writing to your volume the transaction
rate increases now there's a point where
that transaction right tails off and

132
00:18:12.000 --> 00:18:24.000
you're actually submitting data to the
EBS volumes Astor than the EBS volume
can process it now most applications

133
00:18:24.000 --> 00:18:31.000
allow control over the number of
concurrent operations you should
benchmark with different settings and if

134
00:18:31.000 --> 00:18:37.000
you're writing your own application
ensure that you're able to handle
concurrent requests to EBS now you can

135
00:18:37.000 --> 00:18:42.000
think of this parallelism and increasing
queued up and increasing the number of
threads that are writing to the my

136
00:18:42.000 --> 00:18:57.000
seeker to your underlying storage
similar to the gears on my cal
spike all right so now that we've taken

137
00:18:57.000 --> 00:19:06.000
a look at IO let's look at the instance
in the network link now I mentioned
before that was a surprisingly common

138
00:19:06.000 --> 00:19:18.000
choice and the m24 extra-large was
released in 2009 with an intel xeon cpu
early last last year we released the r3

139
00:19:18.000 --> 00:19:25.000
family to replace as the next generation
in our high memory instance families and
so the r32 extra-large has very similar

140
00:19:25.000 --> 00:19:31.000
specs to the m24 extra-large now don't
get confused by the 2x large for x-large
differentiation these really are

141
00:19:31.000 --> 00:19:39.000
equivalent to each other the important
thing to notice here and one thing that
I think is really cool is you get better

142
00:19:39.000 --> 00:19:47.000
performance at twenty-eight cents an
hour less and so that's if you're
running that instance 24-7 for an entire

143
00:19:47.000 --> 00:19:56.000
month that comes out to about two
hundred dollars a month so alongside of
choosing your instance you need to

144
00:19:56.000 --> 00:20:03.000
choose the attributes that are important
for the performance of that instance and
as it pertains to EBS that attribute is

145
00:20:03.000 --> 00:20:15.000
EBS optimized with EBS optimized
instances we allocate a separate amount
of bandwidth just for EBS traffic and so

146
00:20:15.000 --> 00:20:22.000
if you're not using EBS optimized what
happens is the application the internet
the network traffic going to your

147
00:20:22.000 --> 00:20:28.000
application actually shares that network
with the EBS volume and so some days you
may have great performance on your best

148
00:20:28.000 --> 00:20:34.000
volume some days you may not and you
really don't know is it somebody driving
a whole lot of load to your application

149
00:20:34.000 --> 00:20:40.000
or is it your application driving load
to the EBS volume or is the EBS volume
not performing well and not performing

150
00:20:40.000 --> 00:20:51.000
to what you need EBS optimized instances
remove some of that confusion and now
these are EBS optimizing our newer

151
00:20:51.000 --> 00:20:58.000
generation instances are actually EBS
optimized by default and this includes
our m4 c4 and d2 instance families

152
00:20:58.000 --> 00:21:08.000
and the it extra large instances
actually have a 10 gigabit network the
the EBS optimized by default larger

153
00:21:08.000 --> 00:21:16.000
instances also have an additional EDS
bandwidth for the ones that that have
just the shared 10 gigabit network it's

154
00:21:16.000 --> 00:21:24.000
a lot of traffic and a lot of room and
so it has the same caveat of an on EBS
optimized instant but there's a lot of

155
00:21:24.000 --> 00:21:32.000
buffer there and this is where you're
going to get the maximum i 0 and maximum
I ops from your instance each eight

156
00:21:32.000 --> 00:21:42.000
extra large instance can support
approximately forty eight thousand I ops
and that's if you're doing 16 k io so if

157
00:21:42.000 --> 00:21:50.000
you're not using EBS optimized today
it's really easy to change all you have
to do is stop your instance and that can

158
00:21:50.000 --> 00:21:58.000
be done either in the CLI or the console
modify the instance attribute and
restart the instance it's pretty

159
00:21:58.000 --> 00:22:05.000
painless just a little bit of downtime
just like a reboot and it doesn't take a
significant amount of time so let's

160
00:22:05.000 --> 00:22:15.000
update our benchmark configuration the
only thing I've changed here is that I'm
using an r32 extra-large now and just

161
00:22:15.000 --> 00:22:25.000
with that one simple change I've gotten
a twenty-five percent increase in
transactions so another example of this

162
00:22:25.000 --> 00:22:31.000
and something that one of our customers
Pearson has allowed us to do or this has
allowed them to do recently we worked

163
00:22:31.000 --> 00:22:39.000
with them to switch their m1 fleet to m3
s and T twos and they saved more than
ten percent on their bill because of the

164
00:22:39.000 --> 00:22:49.000
extra performance that he they could get
from the newer instance types I think
that's super cool so AWS has a few

165
00:22:49.000 --> 00:22:58.000
different instance two families and they
have a different balance of compute
memory some of them are mixed but what

166
00:22:58.000 --> 00:23:04.000
you probably want to do is make sure
that you're choosing the right instance
an instance family for your workload

167
00:23:04.000 --> 00:23:10.000
you're not going to want to choose a
20,000 I ops volume and try and attach
it to a t2 micro instance

168
00:23:10.000 --> 00:23:17.000
probably not going to get the
performance you're expecting once you've
chosen that family and that that right

169
00:23:17.000 --> 00:23:25.000
mixture of CPU and memory it to ensure
the best performance you should select
the current generation of that instance

170
00:23:25.000 --> 00:23:41.000
family alright so we've talked about IO
the instance the network link its focus
on the EBS volume so I mentioned before

171
00:23:41.000 --> 00:23:49.000
the DBS has a couple different volume
types they really boil down to magnetic
back to an SSD back volumes now when

172
00:23:49.000 --> 00:23:55.000
you're looking at transactional
workloads you're thinking about I ops
and latency and so for those types of

173
00:23:55.000 --> 00:24:03.000
workloads you're going to want to focus
on our SSD backed and now I lump g p 2
and p I ups together here mainly because

174
00:24:03.000 --> 00:24:10.000
the performance is very similar it's the
performance consistency that's different
between the two and so in a benchmark

175
00:24:10.000 --> 00:24:19.000
you're probably not going to notice the
difference between g p 2 and p I ops but
you'll notice that over time also I

176
00:24:19.000 --> 00:24:26.000
recommend that you use a modern file
system modern file systems tend to be
journaled they tend to handle larger

177
00:24:26.000 --> 00:24:35.000
volumes better and more efficiently for
example ext4 and XFS don't actually
allocate the blocks when you do the

178
00:24:35.000 --> 00:24:40.000
initial system call they wait until the
data is all present and then they
allocate the block so that your data is

179
00:24:40.000 --> 00:24:48.000
contained together other file systems
older file systems rather do that as
part of the system call so every read

180
00:24:48.000 --> 00:24:53.000
request or write request that those
blocks are allocated and if you have a
lot of data that's going on they may be

181
00:24:53.000 --> 00:25:02.000
in different parts of your disk now
while there is no need to partition your
volumes just create them and attach them

182
00:25:02.000 --> 00:25:11.000
if your application requires it or your
operating system requires it ensure that
they're aligned on 4k boundaries now

183
00:25:11.000 --> 00:25:18.000
when your partitions are not aligned
what happens is sorry SSDs are 4k page
line and when your partitions are not

184
00:25:18.000 --> 00:25:25.000
aligned EBS has to read at least one
more page to service your eye over
and now will still probably deliver the

185
00:25:25.000 --> 00:25:32.000
I ops that you expect the Layton sees on
those transactions are going to be
higher and so what does that look like

186
00:25:32.000 --> 00:25:39.000
there's tools in both windows and linux
disk part is the tool in Windows that's
a command-line tool to manage your

187
00:25:39.000 --> 00:25:51.000
partitions disk in in Linux so I took a
any BS volume and I put two partitions
on it and so if you notice the first one

188
00:25:51.000 --> 00:26:02.000
starts at sector 2048 it's divisible by
eight which means that it's 4k aligned
now eight that's a weird number linux

189
00:26:02.000 --> 00:26:09.000
shows or displays this in 512 byte
sectors because that's what we
advertised is the native for EBS volumes

190
00:26:09.000 --> 00:26:19.000
and 8 x 512 is 4k if you notice the
second one though the start of that
partition is offset by two sectors or 1k

191
00:26:19.000 --> 00:26:29.000
and so anytime I do an i/o on that
partition I'm going to have to do more
work let's talk a little bit about pre

192
00:26:29.000 --> 00:26:38.000
warming well we've always discussed the
need to pre warm your volumes before you
benchmark but in most cases it's really

193
00:26:38.000 --> 00:26:45.000
not necessary how many people have tried
to pre-warm a really large volume a lot
of you you're probably in a lot of pain

194
00:26:45.000 --> 00:26:54.000
weren't you yeah we noticed that pre
warming large volumes took a really long
time so we've been working and right now

195
00:26:54.000 --> 00:27:02.000
I'm happy to tell you that it's no
longer necessary to pre-warm a newly
created volume all you have to do is

196
00:27:02.000 --> 00:27:12.000
create it attach it mount it and go your
volume is going to achieve its expected
performance now what you might want to

197
00:27:12.000 --> 00:27:19.000
do volume is restored from snapshots are
a little different we still need to get
that data from s3 EBS gets that data in

198
00:27:19.000 --> 00:27:28.000
the background on demand so we'll load
from s3 will pull that data down from s3
if your IO patterns require us to move

199
00:27:28.000 --> 00:27:35.000
one of those segments earlier we'll do
that and so we've done a little bit of
work to improve the performance of

200
00:27:35.000 --> 00:27:40.000
getting data
from s3 but if you're noticing some
performance problems here and some

201
00:27:40.000 --> 00:27:46.000
performance issues one of the things
that you can do is read the areas of
your disc to force us to load those

202
00:27:46.000 --> 00:27:58.000
those portions and that data alright so
one of the cool things about EBS is that
we do offer a different number of volume

203
00:27:58.000 --> 00:28:04.000
types and you can mix and match those
volumes on your instance and so what
I've done now to our configuration I've

204
00:28:04.000 --> 00:28:12.000
built upon the r32 extra-large and have
split the boot volume in the data volume
and so I've created an eight gigabyte

205
00:28:12.000 --> 00:28:22.000
gp2 volume and a 500 gig gp2 volume for
the data and so just by switching from
magnetic to gp2 I've increased

206
00:28:22.000 --> 00:28:35.000
performance nineteen percent or more
than fifty percent over our original
baseline so both g p 2 and p I ops offer

207
00:28:35.000 --> 00:28:47.000
better performance over EBS magnetic
volumes so easy to use our SSD back
volumes one performance matters so last

208
00:28:47.000 --> 00:28:56.000
year EBS changed what we count as an i/o
we change to 256 k io size and so now
it's possible to be both I ops bound and

209
00:28:56.000 --> 00:29:05.000
throughput bond you can send 20,000 ebi
ops to an EBS volume that's provisioned
with 20,000 I ops if you're sending

210
00:29:05.000 --> 00:29:14.000
smaller iOS and if you do the math that
works out to 16 Kos we can also send 320
megabytes per second if you're doing

211
00:29:14.000 --> 00:29:23.000
larger iOS and so 16 k is our crossover
point but if you submit 256k you'll get
320 megabytes per second and if you

212
00:29:23.000 --> 00:29:30.000
submit 4k you'll get 20,000 I ops now if
you're scratching your head about what I
said before that we've optimized in your

213
00:29:30.000 --> 00:29:39.000
instance and for 128 k OS let me explain
that a little bit in the background if
you're submitting sequential i/o EBS

214
00:29:39.000 --> 00:29:45.000
will merge that I 0 for you so even if
you're doing small sequential iOS will
try to gather up as much of that as we

215
00:29:45.000 --> 00:29:55.000
can to make a 256 k io
to give you the throughput that you're
expecting so what does this mean if

216
00:29:55.000 --> 00:30:02.000
you've got a smaller provision labs
volume one that may not have our full
limits of 8,000 or 20,000 I ops so in

217
00:30:02.000 --> 00:30:09.000
this example I'm using a volume
provision with 8,000 I ops and I'm able
to drive 8,000 I ops whether i'm doing

218
00:30:09.000 --> 00:30:18.000
8k 16 k or 32 k because those are all
underneath our throughput limits but
what I'm not able to do is submit 16,000

219
00:30:18.000 --> 00:30:24.000
I ops because especially if they're
random we're not going to be able to
merge those and that's beyond the

220
00:30:24.000 --> 00:30:33.000
capabilities of your volume similarly
for a throughput workload if your i/o
size is larger than we can you can't

221
00:30:33.000 --> 00:30:43.000
submit eight thousand 64k iOS 512
megabytes per second volume is only
capable of 320 megabytes per second and

222
00:30:43.000 --> 00:30:53.000
so in this case what your application
would see is 5064 kios but what if
that's not enough what if you need more

223
00:30:53.000 --> 00:31:00.000
than 16 terabytes of storage what if you
need more than 20,000 I ops what if you
need more than 320 megabytes per second

224
00:31:00.000 --> 00:31:07.000
well one of the things that you can do
within your instance is you can raid and
when we talk about raid we're usually

225
00:31:07.000 --> 00:31:15.000
talking about raid 0 increasing capacity
or performance rarely we want to talk
about redundancy take a moment to dive

226
00:31:15.000 --> 00:31:24.000
into that when you do a raid one or a
mirror within your instance every right
that you write to your EBS volume has to

227
00:31:24.000 --> 00:31:31.000
be written twice and so you're going to
effectively have the bandwidth of your
EBS optimized instance now EBS already

228
00:31:31.000 --> 00:31:40.000
has a durability that's greater than a
hard drive if that's not good enough for
you what we recommend is that you do

229
00:31:40.000 --> 00:31:46.000
application level redundancy and even
better if you're doing that to a
different availability zone it'll give

230
00:31:46.000 --> 00:31:54.000
you a more available service the other
important thing to remember is that when
your striping volumes together you don't

231
00:31:54.000 --> 00:32:00.000
want to mix vol types you don't want to
create a raid set with six magnetic
volumes and 3gp two volumes

232
00:32:00.000 --> 00:32:05.000
you're probably not going to get the
performance you're expecting out of that
your performance is going to look more

233
00:32:05.000 --> 00:32:12.000
like the magnetic volume than it does
the gp2 volume when you do stripe a
volume you need to take some special

234
00:32:12.000 --> 00:32:21.000
attention when you're taking snapshots
and so for a database you're going to
want to flush and lock your tables the

235
00:32:21.000 --> 00:32:26.000
file system you might be able to sync
your fries and then you can do the
snapshot of all the volumes together and

236
00:32:26.000 --> 00:32:34.000
this will give you a point in time
snapshot now when that snapshot api
called returns to create snapchat API

237
00:32:34.000 --> 00:32:41.000
returns that means that it's safe to
resume I oh we've recorded all of the
data that we need to record to complete

238
00:32:41.000 --> 00:32:53.000
those snapshots now many journal file
systems and databases will work without
this but what I really want you to do if

239
00:32:53.000 --> 00:32:58.000
you're going to rely on that I want you
to test it before you rely on it in a
failure scenario I don't want you to be

240
00:32:58.000 --> 00:33:10.000
sad so let's revisit our system we've
optimized everything we've got the right
ec2 instance with enough EBS optimized

241
00:33:10.000 --> 00:33:18.000
bandwidth the right EBS volumes and our
application is tuned to drive a bunch of
i/o so we've got a nice balance system

242
00:33:18.000 --> 00:33:25.000
we've maximized dc2 and EBS performance
how do we ensure that we maintain this
performance and so one of the things

243
00:33:25.000 --> 00:33:30.000
that we've got within amazon is our
cloud watch service now if you're not
using cloud watch today I highly

244
00:33:30.000 --> 00:33:40.000
recommend it Claud watch provides
metrics for all AWS services and EBS is
no different you can take a look at the

245
00:33:40.000 --> 00:33:49.000
metrics for your volume determine if
your volume or volumes are performing as
expected a tip here all the EBS metrics

246
00:33:49.000 --> 00:33:54.000
are priests or prefixed with the word
volume so there's symmetrix in there
that are related to your instance that

247
00:33:54.000 --> 00:34:06.000
are thats a disk i/o and disagreed right
those are actually your local instant
storage and not your EBS volumes so to

248
00:34:06.000 --> 00:34:12.000
show you what it looks like when you're
exceeding the EBS optimized limits of
your instance

249
00:34:12.000 --> 00:34:19.000
I've taken the same two thousand p I ops
volume and attached it to three
different instances the first line

250
00:34:19.000 --> 00:34:26.000
you'll notice that i'm only getting 128
megabytes per second that's because i
attached it to an m4 to extra-large and

251
00:34:26.000 --> 00:34:34.000
that's all the EBS optimized bandwidth
that instance type supports now i bumped
up the size to an m4 for extra-large and

252
00:34:34.000 --> 00:34:41.000
i'm still getting great performance i'm
just still limited by that instance 256
megabytes per second if i go all the way

253
00:34:41.000 --> 00:34:49.000
up to an m4 10 x large i'm getting the
capabilities of the volume and the m4 10
x large actually has even more

254
00:34:49.000 --> 00:35:00.000
capability if you want to attach more
volumes to it now cloud watch metrics
are provided on all EBS volumes for

255
00:35:00.000 --> 00:35:04.000
provision I ops Williams they're
provided at a one-minute granularity and
for everything else there are five

256
00:35:04.000 --> 00:35:11.000
minute granularity and those are free
within your cloud watch Council but if
Claude watch isn't enough if you need

257
00:35:11.000 --> 00:35:18.000
something more frequently there's a
number of tools that you can use to even
monitor the performance a little bit

258
00:35:18.000 --> 00:35:27.000
more granular iostat is one of them in
linux and here i've shown an example on
one second boundaries and it's important

259
00:35:27.000 --> 00:35:34.000
to remember with iostat that very first
line that it shows you is going to be an
average of that volumes performance

260
00:35:34.000 --> 00:35:42.000
since the instance booted so it's not a
snapshot in time I estate provide a lot
of information about how many requests

261
00:35:42.000 --> 00:35:50.000
are merged how many requests your
application submitting the queue depth
the average a weight is latency and then

262
00:35:50.000 --> 00:35:56.000
the average request size now the
important thing to remember with
parallel storage systems is that

263
00:35:56.000 --> 00:36:05.000
utilization and service time don't mean
what you think they mean utilization is
actually the amount of time the device

264
00:36:05.000 --> 00:36:13.000
spent servicing at least one I oh
there's no bonus points in utilization
for submitting to iOS or 3 o's so it

265
00:36:13.000 --> 00:36:18.000
doesn't really tell you about the
capabilities of your volume it just
tells you how active your volume is and

266
00:36:18.000 --> 00:36:23.000
the other thing with service time is it
really doesn't do a good job of taking
parallelism into

267
00:36:23.000 --> 00:36:32.000
come if you're submitting 10 iOS all at
the same time and they complete one
millisecond later service time is going

268
00:36:32.000 --> 00:36:42.000
to report that they each took 100
microseconds not really reality so
within your Windows instance for anybody

269
00:36:42.000 --> 00:36:48.000
that's using Windows there's a tool
called perfmon and backing up perfmon it
provides about the same amount of data

270
00:36:48.000 --> 00:36:57.000
is iostat the the windows performance
gathering metric system feeds data into
here and you're actually able to extract

271
00:36:57.000 --> 00:37:04.000
the raw data from perfmon as well so if
you want to do different slicing and
dicing on it more than perfmon can do

272
00:37:04.000 --> 00:37:13.000
that's available to you as well so
really the important things here are to
select the right instance for your

273
00:37:13.000 --> 00:37:21.000
workload don't take that T to micro and
attach a 20,000 pios volume to it select
the right volume for your workload if

274
00:37:21.000 --> 00:37:29.000
you're concerned about latency and I ops
might want to consider an SSD back
volume increase the parallelism of i/o

275
00:37:29.000 --> 00:37:37.000
and make sure that your your volume and
your whole system is performing as you
expected by monitoring with Claude much

276
00:37:37.000 --> 00:37:47.000
now for another deep dive tomorrow
there's a talk about EBS Amazon EBS Inca
standard this is specific to Cassandra

277
00:37:47.000 --> 00:37:54.000
and shows how CrowdStrike was able to
get 1 million writes per second using
EBS volumes on sixty nodes so I've got

278
00:37:54.000 --> 00:38:01.000
some friends with from EBS and we're
happy to take some questions one on one
after this session but thank you all for
attending today and hopefully this was
helpful