WEBVTT FILE

1
00:00:00.000 --> 00:00:09.000
good morning everybody welcome to the
last day of reinvent I'm glad so many of
you made the maybe sometimes tough

2
00:00:09.000 --> 00:00:14.000
decision to get out of bed and come here
this morning so thank you for coming
here today to talk about the relational

3
00:00:14.000 --> 00:00:22.000
database service and take a deeper dive
under the covers of what RDS has to
offer my name is Scott Ward I'm a

4
00:00:22.000 --> 00:00:28.000
solution architect at EWS I work on the
partner team based out of Seattle I'm
going to be joined here throughout the

5
00:00:28.000 --> 00:00:36.000
day by Katie Singh who is also a
solution architect on the partner team
and based out of San Francisco quick

6
00:00:36.000 --> 00:00:44.000
pull from the audience who here today is
running RTS using RDS okay who here
today is running a relational database

7
00:00:44.000 --> 00:00:55.000
but on ec2 ok and then who's looking to
migrate to RTS whether you're on ec2 or
not on ec2 in like the next 12 months ok

8
00:00:55.000 --> 00:01:01.000
cool I think we've got some content in
this presentation that's going to apply
to all three of those scenarios to kind

9
00:01:01.000 --> 00:01:08.000
of help you better understand what RDS
kit can do it and some of the ways you
can leverage it and use RDS as a service

10
00:01:08.000 --> 00:01:15.000
we will leave some time for Q&A here
today and if we if we burn through that
time we'll happily stand down here and

11
00:01:15.000 --> 00:01:25.000
continue to answer further questions at
the end of the session cool so this is a
deep dive so we don't need to spend a

12
00:01:25.000 --> 00:01:32.000
lot of time on the value prop of RDS but
just very quickly that there's no
infrastructure management with RDS we

13
00:01:32.000 --> 00:01:39.000
take care of ordering and managing the
infrastructure for that RDS is very cost
effective because it runs with a for the

14
00:01:39.000 --> 00:01:45.000
database instance with a pay-as-you-go
model and you only pay for the amount of
storage that you actually provision if

15
00:01:45.000 --> 00:01:51.000
you're using third-party applications or
if you built your own custom
applications that are using a relational

16
00:01:51.000 --> 00:01:57.000
database there's a very good chance that
they will continue to work against a
database running on RDS you get instant

17
00:01:57.000 --> 00:02:04.000
provisioning with RDS so when you want a
new database with a few clicks of a
button or a command-line call you have a

18
00:02:04.000 --> 00:02:10.000
database up and running and ready for
you to log into in just a few minutes
and you can scale up and scale down with

19
00:02:10.000 --> 00:02:16.000
RDS you can resize your database
instance to get
a appropriate configuration of CPU and

20
00:02:16.000 --> 00:02:25.000
memory and you don't have to worry about
going and finding more infrastructure to
support those scaling efforts now RDS is

21
00:02:25.000 --> 00:02:31.000
a managed service so there are some
trade-offs that go with that managed
service it's got a fully managed host an

22
00:02:31.000 --> 00:02:37.000
operating system so the good thing is
you don't have to burn operational
effort to actually manage those

23
00:02:37.000 --> 00:02:44.000
components but what it means is there
that you know you don't get access to
that host operating system we control

24
00:02:44.000 --> 00:02:49.000
that access so you're going to have some
limited ability to maybe modify
configuration settings that you would

25
00:02:49.000 --> 00:02:55.000
normally go to the operating system and
modify yourself and that may mean that
there's some some functions or key

26
00:02:55.000 --> 00:03:02.000
functionality in the database that maybe
isn't available to you we're working to
bridge those gaps still as a service but

27
00:03:02.000 --> 00:03:07.000
but pay attention to those and make sure
you look at those if you're just moving
to RDS and then the storage is also

28
00:03:07.000 --> 00:03:14.000
fully managed with RDS once again you
don't have the operational burden of
having to deal with monitoring and

29
00:03:14.000 --> 00:03:22.000
managing the storage but because it's
fully managed there's some limits if
you're using Aurora you get 64 terabytes

30
00:03:22.000 --> 00:03:28.000
of storage pretty good it could amount
with Microsoft sequel server you can
have up to four terabytes of storage and

31
00:03:28.000 --> 00:03:34.000
with the remaining engines you can have
up to six terabytes of storage so what
that means is that growing your

32
00:03:34.000 --> 00:03:39.000
databases of process you have to make
some decisions about how much storage
you're going to provision and then you

33
00:03:39.000 --> 00:03:45.000
have to make some decisions about when
you're going to provision more storage
and if you get to the end and you've

34
00:03:45.000 --> 00:03:50.000
used up all the storage available you
have to make some more decisions about
am I going to delete data am I going to

35
00:03:50.000 --> 00:03:56.000
archive data do i need to come up with a
charting strategy in order to create
another database and continue to have

36
00:03:56.000 --> 00:04:06.000
enough storage available to support my
application this is a view of all the
RDS engines that are out there today so

37
00:04:06.000 --> 00:04:13.000
on the commercial side we have oracle
and microsoft sequel server open source
my sequel postgres and Mariah DB and in

38
00:04:13.000 --> 00:04:20.000
the cloud native category we have Amazon
Aurora which is supporting my sequel and
now as of Wednesday the postgres version

39
00:04:20.000 --> 00:04:27.000
of Aurora as well who here is like
really excited to get their hands on the
postgres side yeah

40
00:04:27.000 --> 00:04:32.000
having done this talk several times
throughout the year like that is a very
common question we got from customers

41
00:04:32.000 --> 00:04:38.000
and it backs up a lot of what Andy said
so very excited to see what people can
do with that when they get their hands

42
00:04:38.000 --> 00:04:51.000
on it so security is a top priority at
AWS and we take a lot of pride and we
put make it really job zero to ensure

43
00:04:51.000 --> 00:04:57.000
that our customers are operating in his
safe and secure and environment as
possible and so with that in mind

44
00:04:57.000 --> 00:05:02.000
there's a lot of different things you
can do security wise when it comes to
RDS to make sure that you're operating

45
00:05:02.000 --> 00:05:10.000
with the right security profile for you
it starts out with a neck working that's
tied to your database so as many of you

46
00:05:10.000 --> 00:05:16.000
know we have a virtual private cloud and
when you launch an RDS instance that
instance launches inside a virtual

47
00:05:16.000 --> 00:05:22.000
private cloud and with the virtual
private cloud you can define your own
private network address space with

48
00:05:22.000 --> 00:05:29.000
inside the AWS cloud you can also carve
that up even further into different
subnets across different availability

49
00:05:29.000 --> 00:05:34.000
zones so when you've got your database
up and running and it's running inside
your virtual private cloud there's lots

50
00:05:34.000 --> 00:05:40.000
of different ways that you can manage
connectivity and control access into
your database you have a double us

51
00:05:40.000 --> 00:05:46.000
Direct Connect which will let you to
allow you to connect your on-premise
data center with an AWS region for a

52
00:05:46.000 --> 00:05:55.000
high-speed throughput you can create a
VPN connection to have a secure tunnel
between your virtual private cloud and

53
00:05:55.000 --> 00:06:01.000
your data center or your corporate
offices you could peer multiple V pcs
together either within an AWS account or

54
00:06:01.000 --> 00:06:07.000
across different accounts so if you've
got different databases or different
applications in other V pcs you can peer

55
00:06:07.000 --> 00:06:13.000
them with a VPC that's maybe hosting an
RDS instance and still be able to access
them you have routing rules where you

56
00:06:13.000 --> 00:06:19.000
can define and decide how traffic is
routed in your v pc and you can attach
an internet gateway to it to actually

57
00:06:19.000 --> 00:06:27.000
allow your database to have to be able
to reach the public internet if it needs
to building on that and going a step

58
00:06:27.000 --> 00:06:34.000
lower we have security groups around
your databases so this is a virtual
firewall around your database it's it's

59
00:06:34.000 --> 00:06:40.000
very similar to what we have in ec2 and
it gives you the ability to define
inbound and

60
00:06:40.000 --> 00:06:45.000
found traffic rules as far as what is
allowed into your database and what is
allowed out and you can define that at

61
00:06:45.000 --> 00:06:51.000
the protocol the port and the source
level and with the source level you have
a fair amount of flexibility you can

62
00:06:51.000 --> 00:06:57.000
define a single IP address you can
define a range of IP addresses or you
could actually define another security

63
00:06:57.000 --> 00:07:04.000
group as the source so if you're running
a multi-tiered architecture with the
database as part of that you can

64
00:07:04.000 --> 00:07:11.000
actually define the source as a security
group of the tier above your database
that actually needs to talk to your

65
00:07:11.000 --> 00:07:18.000
database and so it allows you to and to
ensure that the components that need to
talk to the database can but that other

66
00:07:18.000 --> 00:07:24.000
components or other users can't
circumnavigate your security rules as
far as how you actually want your

67
00:07:24.000 --> 00:07:33.000
database to be accessed ews offers
Identity and Access Management is a
service to control access and

68
00:07:33.000 --> 00:07:39.000
permissions within your AWS account
against the AWS services you're using
and RDS is one of those services you can

69
00:07:39.000 --> 00:07:47.000
certainly use I am against one of the
key things to call out here though is
that I am doesn't control who can log in

70
00:07:47.000 --> 00:07:54.000
to your database you still need to focus
on using the grants functionality that
exists within your database engine to

71
00:07:54.000 --> 00:08:01.000
define users and their passwords and
what access those users or the
applications have within your database

72
00:08:01.000 --> 00:08:09.000
Identity and Access Management is going
to control what you could do against the
actual RDS service so defining who can

73
00:08:09.000 --> 00:08:17.000
create a database who can modify the
configuration of a database as far as
the service goes or delete a database

74
00:08:17.000 --> 00:08:24.000
from the RDS service one of the cool
things with that is that besides monitor
you know meant controlling those types

75
00:08:24.000 --> 00:08:30.000
of permissions if you're using tags on
your RDS instance you can actually
define access policies that go down to

76
00:08:30.000 --> 00:08:38.000
the tag level so if you want to say that
a support person can only maybe modify
development databases versus production

77
00:08:38.000 --> 00:08:45.000
databases you can actually go that fine
grain of your policies around how you
use and how people access the RDS

78
00:08:45.000 --> 00:08:54.000
service in your account
one of the reasons that people are so
concerned or focused on security when it

79
00:08:54.000 --> 00:09:00.000
comes to running on AWS is that they
have compliance needs that they need to
meet so we have lots of different

80
00:09:00.000 --> 00:09:08.000
customers across the enterprise the the
public sector and the startup space who
are operating in industries that require

81
00:09:08.000 --> 00:09:15.000
that they meet certain requirements in
order to be certified as running you
know being allowed to run for that

82
00:09:15.000 --> 00:09:21.000
particular industry so what AWS has done
is we've gone and we've worked with
these third-party organizations that you

83
00:09:21.000 --> 00:09:27.000
see here on the slide and we work with
them to help them understand the RDS
service and make sure that it is running

84
00:09:27.000 --> 00:09:34.000
and meets or even potentially exceeds
the requirements they have around how
the service needs to be operated and how

85
00:09:34.000 --> 00:09:41.000
it needs to be secured against their
requirements and so what that means is
that you as a customer have the ability

86
00:09:41.000 --> 00:09:49.000
to run your applications on top of RDS
and achieve a compliance certification
it doesn't mean that you don't have any

87
00:09:49.000 --> 00:09:55.000
responsibilities though your security
professionals they don't have to worry
about the infrastructure of the RDS

88
00:09:55.000 --> 00:10:00.000
service but they still need to focus
their time on your applications and
making sure that they're still compliant

89
00:10:00.000 --> 00:10:06.000
and they meet the requirements of the
organization that you're working with
and you're then able to take the

90
00:10:06.000 --> 00:10:12.000
third-party attestations that we can
provide around how RDS is meeting the
requirements of a particular compliance

91
00:10:12.000 --> 00:10:18.000
organization you can marry that up with
your audit findings from your
application and have a complete view to

92
00:10:18.000 --> 00:10:25.000
show that you are fully compliant with
the industry or the organization that
you're operating against this is a view

93
00:10:25.000 --> 00:10:33.000
of what we have for compliance for each
of the database engines today with the
newest one being Aurora having HIPAA baa

94
00:10:33.000 --> 00:10:39.000
and postgres segal having hip a baa that
was announced on Tuesday one
clarification here the Aurora one

95
00:10:39.000 --> 00:10:48.000
currently only applies to the my sequel
compatible Aurora it does not apply to
the postgres Aurora yet and we are you

96
00:10:48.000 --> 00:10:53.000
know we're working to bridge the gap
with all these engines to help grow that
this list of compliance bodies that all

97
00:10:53.000 --> 00:11:02.000
the engines cover so over time you
should expect to see this list to grow
some of these compliance organizations

98
00:11:02.000 --> 00:11:07.000
have requirements around protection and
encryption of data some of them say that
you actually have to have your data

99
00:11:07.000 --> 00:11:14.000
encrypted in transit so with RDS you can
actually enable SSL for all the RDS
engines to ensure that you have your

100
00:11:14.000 --> 00:11:20.000
data encrypted coming into and out of
the database to help ensure that your
meeting compliance requirements whether

101
00:11:20.000 --> 00:11:30.000
they be internal or external to ensure
that your data is protected all it's in
transit another common thing that we see

102
00:11:30.000 --> 00:11:37.000
both for internal and external
compliance requirements is the need to
have data protected and encrypted at

103
00:11:37.000 --> 00:11:43.000
rest so in general whatever possible at
AWS we recommend that customers encrypt
their data wherever they can to help it

104
00:11:43.000 --> 00:11:49.000
increase in secure their data and
already us provide you a couple
different ways that you can actually go

105
00:11:49.000 --> 00:11:57.000
through and implement this protection if
you're using Oracle or sequel server and
you want to use or are using transparent

106
00:11:57.000 --> 00:12:05.000
data encryption you can actually take
and implement that functionality on an
RDS database on the Oracle side you get

107
00:12:05.000 --> 00:12:12.000
the extra ability to actually take and
store your keys in a cloud HSM module as
opposed to just sitting there on the

108
00:12:12.000 --> 00:12:19.000
database server so if you have some
requirements or would like to use an HSM
as part of your implementation you can

109
00:12:19.000 --> 00:12:27.000
do that with the Oracle implementation
then for all the engines that that RDS
supports you can also implement at rest

110
00:12:27.000 --> 00:12:34.000
encryption using AWS key management
service so the key management services
AWS managed service that takes care of

111
00:12:34.000 --> 00:12:42.000
all the scalability durability
reliability key rotation key deletion
key creation that you might expect from

112
00:12:42.000 --> 00:12:48.000
from a normal key management service and
it allows you to focus on building your
applications and integrating with the

113
00:12:48.000 --> 00:12:55.000
database without having to invest all
the operational overhead and design of
actually creating your own key

114
00:12:55.000 --> 00:13:02.000
management service it gives you
protection in RDS of the underlying
storage that's holding your database

115
00:13:02.000 --> 00:13:10.000
your data it also actually provides
protection for the automated backups
that RDS gives you for the read replicas

116
00:13:10.000 --> 00:13:15.000
that you can implement with RDS and for
the snapshots
you might create against your database

117
00:13:15.000 --> 00:13:24.000
those will also all be encrypted kms
uses industry standard aes 256-bit
encryption and turning on an enabling

118
00:13:24.000 --> 00:13:30.000
encryption with an RDS using kms is very
straightforward when you're in the
management console there's one drop down

119
00:13:30.000 --> 00:13:38.000
that's enable encryption you choose yes
or no if you choose yes and you do
nothing else the RDS service will create

120
00:13:38.000 --> 00:13:47.000
a service key in your account with key
management service and that key is tied
and owned by your account it is not does

121
00:13:47.000 --> 00:13:52.000
not live in another AWS account it's not
owned by somebody else it is tied to
your account you have full ownership of

122
00:13:52.000 --> 00:13:59.000
it that key is then used to vend up data
keys that are used to encrypt and
protect your databases and each database

123
00:13:59.000 --> 00:14:07.000
would get its own data keys so each
database would running be running with
its own encryption key when you go in

124
00:14:07.000 --> 00:14:12.000
and you launch database instance here's
what happens is the the RDS service is
going to stand up and create the actual

125
00:14:12.000 --> 00:14:18.000
database instance it's going to see that
you've enabled key management and
encryption it's going to reach out to

126
00:14:18.000 --> 00:14:26.000
the KMS service and say hey I'd like to
use this key kms is going to verify that
that database actually has permission to

127
00:14:26.000 --> 00:14:34.000
use that master key when it verifies
that and it's all good it will then back
a data key to the RDS service it will

128
00:14:34.000 --> 00:14:42.000
store that key in memory the database
instance it will then use that key to
encrypt and decrypt your data as you are

129
00:14:42.000 --> 00:14:49.000
using the database an important thing to
call it here is that I talked about the
the service key that you get in KMS if

130
00:14:49.000 --> 00:14:57.000
you want to actually use a different key
you can actually either use KMS to
create your own master key or if you

131
00:14:57.000 --> 00:15:02.000
have a key that you've been using you
can actually import that key into kms
you can actually choose to use those

132
00:15:02.000 --> 00:15:10.000
keys instead of the service key if you'd
like to when you're encrypting your
database so i talked about how you know

133
00:15:10.000 --> 00:15:14.000
how it is when you actually enable
encryption this is a screenshot of the
management console and in the upper

134
00:15:14.000 --> 00:15:21.000
right you can see there's just that
drop-down of the yes option or enabling
encryption the default there once again

135
00:15:21.000 --> 00:15:28.000
that AWS / RDS that's the service
specific key or you can enter the amazon
resource name

136
00:15:28.000 --> 00:15:33.000
of a different key that you'd like to
use that's in your account for
encryption it's also very straight

137
00:15:33.000 --> 00:15:37.000
forward to actually enable this at the
command line if you're doing some
automation around how you create your

138
00:15:37.000 --> 00:15:45.000
databases so there's one extra parameter
called storage encrypted that one will
use the default service key and if you

139
00:15:45.000 --> 00:15:51.000
want to use a specific key you all you
use the storage encrypted option along
with the key ID of the key that you'd

140
00:15:51.000 --> 00:16:00.000
like to use from KMS so when you're
using RDS and KMS together as a couple
of hints that i'd like to make sure

141
00:16:00.000 --> 00:16:06.000
you're aware of you can only encrypt
when you actually create a new database
so if the database is already up and

142
00:16:06.000 --> 00:16:11.000
running you can't actually just turn
encryption on and once the database is
on an up and running and you have

143
00:16:11.000 --> 00:16:17.000
encryption turned all you can't turn
encryption off you're mastering your
read replica must be encrypted and the

144
00:16:17.000 --> 00:16:22.000
RDS service actually takes care of that
for you so if you've already encrypted
your master database and you go and

145
00:16:22.000 --> 00:16:27.000
create another read replica if the
service will automatically enable
encryption for that read replica as well

146
00:16:27.000 --> 00:16:35.000
if you have any unencrypted snap shots
shots sitting around you can actually
use them to create encrypted databases

147
00:16:35.000 --> 00:16:42.000
so if you have an Aurora snapshot that's
unencrypted when you use that snapshot
to create a new database cluster there's

148
00:16:42.000 --> 00:16:46.000
actually now an option to choose that
you want that database encrypted and you
can provide the right key that you want

149
00:16:46.000 --> 00:16:52.000
to use you know how have an encrypted
arroyo database if you have a snapshot
that's unencrypted for any of the other

150
00:16:52.000 --> 00:16:58.000
engines you can actually take that
snapshot use the copy snapshot
functionality and during that copy

151
00:16:58.000 --> 00:17:04.000
process you can actually choose that you
want to have encryption for that new
snapshot choose the key you want to use

152
00:17:04.000 --> 00:17:09.000
and then you can take that new snapshot
to actually launch a new database
instance you know have a encrypted

153
00:17:09.000 --> 00:17:16.000
database running as well you currently
can't take a my sequel encrypted
snapshot and use it to create an arroyo

154
00:17:16.000 --> 00:17:22.000
instance and you can't use an Aurora
encrypted snapshot to create a my sequel
instance an RDS and you can't take any

155
00:17:22.000 --> 00:17:29.000
encrypted snapshots and crappie them to
in a different AWS region right now and
we can't you can't do any read replica

156
00:17:29.000 --> 00:17:36.000
rep in other regions if you're using an
encrypted snap encrypted database at
this point that's a very common ass from

157
00:17:36.000 --> 00:17:41.000
our customers be able to solve the
product teams I'm sure are working on
that and trying to find other

158
00:17:41.000 --> 00:17:47.000
right way to make that possible with
that I'd like to hand it over to Katie
for just a little bit and I'll be back a

159
00:17:47.000 --> 00:18:05.000
little later thank you Scott
so monitoring your database to see how
its performing to track some key metrics

160
00:18:05.000 --> 00:18:12.000
to know that these key metrics are
within bound to get notified if some of
these metrics get out of bounds and

161
00:18:12.000 --> 00:18:19.000
hopefully to automate if something bad
happens because these metrics are outer
bound are all critical parts of managing

162
00:18:19.000 --> 00:18:27.000
a database these metrics are also
important dinner or apart in in RDS for
scaling operations as well so let's look

163
00:18:27.000 --> 00:18:37.000
at some of the matrix and monitoring
lead features that RDS offers to you for
anyone that is using RDS we offer to you

164
00:18:37.000 --> 00:18:43.000
around 15 to 18 different metrics the
number of metrics depends on the
database instance size that you are

165
00:18:43.000 --> 00:18:52.000
using RDS passes all the information
required for this matrix to the Amazon
Cloud wat service and once it's with

166
00:18:52.000 --> 00:18:59.000
cloud watch you are able to review these
metrics from the monitoring tab within
RDS console from within the cloud watch

167
00:18:59.000 --> 00:19:08.000
console itself or through cloud watch
api's you get these interviews metrics
at 1 minute intervals you get this into

168
00:19:08.000 --> 00:19:14.000
these metrics in a nice graphical format
you can see single graphs multiple
graphs or you can use the cloud watch

169
00:19:14.000 --> 00:19:22.000
api's to bring all this data into your
own logging and monitoring tools when
you get this matrix you also have the

170
00:19:22.000 --> 00:19:28.000
ability to set up cloud watch alarms
what that means is you set up thresholds
on these metrics that are meaningful to

171
00:19:28.000 --> 00:19:38.000
you if the threshold is exceeded because
of any reason you will get notified and
you can use services like Amazon SNS to

172
00:19:38.000 --> 00:19:46.000
take automated actions in case the
threshold is exceeded as well when it
comes to monitoring your databases there

173
00:19:46.000 --> 00:19:55.000
might be a lot of matrix at the host and
operating system level that you might
want to track and monitor in RDS here

174
00:19:55.000 --> 00:20:03.000
you don't have the ability to log into
the host you don't have access to the to
the host operating system as well so to

175
00:20:03.000 --> 00:20:09.000
provide you insights related to to the
host and the host operating system we
offer enhanced monitoring

176
00:20:09.000 --> 00:20:17.000
enhance monitoring provides you about 50
additional metrics that you can track
they are also provided to you we are a

177
00:20:17.000 --> 00:20:24.000
cloud watch you can choose the latency
at which these enhance monitoring
metrics are provided to you default is

178
00:20:24.000 --> 00:20:31.000
60 seconds but you can make it as small
as one second if you want with the nance
monitoring some of the things that you

179
00:20:31.000 --> 00:20:39.000
are able to get to are things like free
memory used memory amount of file system
there to be I've already ended up using

180
00:20:39.000 --> 00:20:46.000
as well so you might be wondering what's
the difference between the basic
monitoring standard monitoring and

181
00:20:46.000 --> 00:20:54.000
enhanced monitoring why are they
different to provide to you the standard
monitoring metrics hypervisor is used

182
00:20:54.000 --> 00:21:02.000
whatever the hypervisor is able to see
is whatever is offered to you we are the
standard monitoring but hypervisor is

183
00:21:02.000 --> 00:21:08.000
not able to get to all the information
in the host and the host operating
system it has a limited functionality so

184
00:21:08.000 --> 00:21:14.000
to provide enhanced monitoring metrics
we actually run a lightweight agent on
the host itself the host which is

185
00:21:14.000 --> 00:21:21.000
hosting your RDS instance and this agent
is able to collect all the information
and provide it to enhance monitoring

186
00:21:21.000 --> 00:21:32.000
which we brought it to you along with
the postgres sequel edition of Aurora we
are also announcing a new monitoring

187
00:21:32.000 --> 00:21:39.000
feature with an RDS which is called
performance insights the goal of
performance insights is to provide

188
00:21:39.000 --> 00:21:48.000
customers with a intuitive graphical
interface that helps them determine
where the performance bottleneck lie and

189
00:21:48.000 --> 00:21:59.000
where they should take some action a lot
of detailed information is is gathered
by lightweight mechanism and we offer

190
00:21:59.000 --> 00:22:09.000
this information to you for up to the
last 35 days so it's difficult to see
this graph right here but the act if you

191
00:22:09.000 --> 00:22:17.000
the y-axis on this graph is the cpu load
and the and the orange and the blue
lines you see our sequel queries so

192
00:22:17.000 --> 00:22:24.000
looking at this graph you can quickly
arrow down the areas where the
performance bottlenecks are and review

193
00:22:24.000 --> 00:22:29.000
which sequel statements are actually
causing all that bottleneck so now you
are quickly able to determine that and

194
00:22:29.000 --> 00:22:37.000
here they will expect on that after this
would be a free feature it's going to
get rolled rolled out in phases

195
00:22:37.000 --> 00:22:48.000
throughout 2017 started with the post
class edition of Aurora when we are
designing an application it's an

196
00:22:48.000 --> 00:22:54.000
application stack we have to make sure
that each layer or each tier in that
application stack is highly available

197
00:22:54.000 --> 00:23:02.000
otherwise the complete application will
not be available for example if you
design the application portion to be a

198
00:23:02.000 --> 00:23:11.000
che but the database is not you will
still see a downtime in case something
bad happens with the database so when we

199
00:23:11.000 --> 00:23:19.000
talk about high availability with RDS we
are talking about the ability for you to
failover in case something bad happens

200
00:23:19.000 --> 00:23:26.000
with your primary instance or the
ability for you to use another database
instance in phase something bad happens

201
00:23:26.000 --> 00:23:34.000
with the primary instance so there are a
few features that RDS offers for high
availability let's look at them let's

202
00:23:34.000 --> 00:23:41.000
start with something simple let's say
that you are launching a new RDS
instance you choose the region you want

203
00:23:41.000 --> 00:23:48.000
to work in you choose the VPC where you
want to deploy this RDS instance in case
you are using a single easy

204
00:23:48.000 --> 00:23:54.000
configuration you'll choose the
availability zone point to the subnet
where you want to launch it and then you

205
00:23:54.000 --> 00:24:01.000
are able to launch your RDS instance in
a single availability zone configuration
now this configuration is just fine I

206
00:24:01.000 --> 00:24:08.000
kept taking the tires you are testing
things out developing something for
example but when it comes to running

207
00:24:08.000 --> 00:24:18.000
production databases the best practice
is to configure your RDS instance in a
multi easy configuration when you launch

208
00:24:18.000 --> 00:24:26.000
a new RDS instance in a multi easy
configuration or you modify an existing
single easy RDS instance into multi easy

209
00:24:26.000 --> 00:24:36.000
what RDS does is it launches standby
replica of your primary instance in a
different availability zone within the

210
00:24:36.000 --> 00:24:43.000
same region and after launching it it's
going to sink in the sleigh replicate
data between your primary node and your

211
00:24:43.000 --> 00:24:52.000
standby node so it is this is
synchronous which means that any
transactions are simultaneously provided

212
00:24:52.000 --> 00:25:00.000
to both the primary as well as the
standby one of the key features this
multi AZ configuration provides to you

213
00:25:00.000 --> 00:25:07.000
it gives you higher durability higher
availability but it also gives you gives
RDS the ability to provide to you

214
00:25:07.000 --> 00:25:15.000
automated failover in case there is
something wrong with the primary
database in instance whether at the

215
00:25:15.000 --> 00:25:21.000
compute layer or at the storage layer or
the primary availability zone has any
issues or there is network connectivity

216
00:25:21.000 --> 00:25:31.000
issue to that primary easy RDS will
automatically flail over to the to the
standby and promote it to be the new

217
00:25:31.000 --> 00:25:39.000
master to do this veil over which is
automated the cname record of your of
your master instance the DB endpoint is

218
00:25:39.000 --> 00:25:47.000
flipped over to the standby and then
there standbys is promoted so this DNS
failover typically takes anywhere from

219
00:25:47.000 --> 00:25:56.000
30 seconds to 2 minutes to happen one of
the cool features is that all of this is
automated since the endpoint itself does

220
00:25:56.000 --> 00:26:04.000
not change you do not have to make any
changes to your applications as soon as
the standby is promoted it can keep

221
00:26:04.000 --> 00:26:17.000
using the database just like it was
already another related concept is that
of I availability in case your primary

222
00:26:17.000 --> 00:26:26.000
database has performance issues because
there are a lot of reads and writes
happening to scale the read capability

223
00:26:26.000 --> 00:26:32.000
of your you can actually do two things
one is you can just scale up your
primary database you just get a bigger

224
00:26:32.000 --> 00:26:41.000
RDS instance but you can also scale out
the raid capability of your database by
launching madrid replicas and then the

225
00:26:41.000 --> 00:26:46.000
read portions of your applications can
point to the
read replicas and the master is

226
00:26:46.000 --> 00:26:53.000
offloaded with the work of just just
doing read transactions so it helps you
scale the performance of a database with

227
00:26:53.000 --> 00:27:03.000
the my sequel Maria DB post-press and
Aurora database engines you can launch
these read replicas within the region or

228
00:27:03.000 --> 00:27:10.000
across regions as well now if you're
launching across regions that gives you
a couple of cool capabilities the first

229
00:27:10.000 --> 00:27:18.000
is that if you have a globally
distributed application if your reads
are our local or closer to where your

230
00:27:18.000 --> 00:27:23.000
application is setting the performance
is going to be better and the other cool
feature is that it's a good tool for you

231
00:27:23.000 --> 00:27:30.000
to have and you're designing disaster
recovery right solutions because these
replicas can also be used to failover

232
00:27:30.000 --> 00:27:41.000
and become a master as well you can get
masters out of these our eyes design
differently so I'm going to spend a

233
00:27:41.000 --> 00:27:48.000
couple of minutes talking about how odd
shape works with aurora aurora uses a
decoupling and service-oriented

234
00:27:48.000 --> 00:27:57.000
architecture techniques to break out
database functionality into different
smaller services logging and storage in

235
00:27:57.000 --> 00:28:03.000
aurora is a different service caching is
another service i'm not going to get
into caching right here we need to just

236
00:28:03.000 --> 00:28:11.000
talk about the storage tier here within
Roura storage is handled by six
different storage nodes these six

237
00:28:11.000 --> 00:28:19.000
different storage nodes are across three
different availability zones in a region
so you get a lot lot more durability and

238
00:28:19.000 --> 00:28:26.000
availability this way and this six
different storage nodes are only a
peer-to-peer gossip network and they

239
00:28:26.000 --> 00:28:33.000
talk to each other to come up to speed
and they use a quorum system if four of
this six storage node says that a the

240
00:28:33.000 --> 00:28:39.000
acknowledged a right then the right is
committed so this makes a raw
performance very fast another cool

241
00:28:39.000 --> 00:28:46.000
feature here is that these storage nodes
continuously and incrementally backup
your data to s3 and as3 as we know is

242
00:28:46.000 --> 00:28:56.000
designed for 11 lines of durability the
key thing here is continuously and
incrementally you don't have to schedule

243
00:28:56.000 --> 00:29:06.000
you don't have to schedule these backups
at all and at the database tier with in
aurora you can spin up to 15 different

244
00:29:06.000 --> 00:29:12.000
raid replicas these different 15
different read replicas can be in
different availability zones in this

245
00:29:12.000 --> 00:29:18.000
example I am showing three az's one is
the primary node or the master node and
then we have two different read replicas

246
00:29:18.000 --> 00:29:27.000
the cool thing about these read replicas
is that they offload read load from your
database just like in in other day RDS

247
00:29:27.000 --> 00:29:35.000
database engines but these read replicas
are also failover targets one of these
read replicas can be promoted to be the

248
00:29:35.000 --> 00:29:41.000
master or any of these can be promoted
to be the master in case something bad
happens with the master node now which

249
00:29:41.000 --> 00:29:47.000
one is going to get promoted depends on
the priority you assign and these
replicas can be of different sizes these

250
00:29:47.000 --> 00:29:55.000
can be different sized instances so you
can choose if my master running in AZ a
goes down promote my read replica

251
00:29:55.000 --> 00:30:05.000
sitting in AZ 3 which is the same size
to be the new master so and this
failover is quite fast as well with that

252
00:30:05.000 --> 00:30:18.000
I'm going to hand it over to Scott and I
will be back to than to conclude this
presentation great thank you so scaling

253
00:30:18.000 --> 00:30:28.000
your database to keep up with demand is
important part of operating your overall
application or your workload and as you

254
00:30:28.000 --> 00:30:34.000
if you recall in one of the earlier
slides I talked about the you know one
of the key value props I've already s is

255
00:30:34.000 --> 00:30:40.000
the ability to actually be able to scale
up and scale down actually quite easily
so we're going to dive a little bit

256
00:30:40.000 --> 00:30:51.000
deeper into one of some of the things
you can do around scaling when it comes
to RDS so why would we scale why do

257
00:30:51.000 --> 00:31:01.000
people want to scale first natural one
is just being able to handle changes in
load over time being able to handle a

258
00:31:01.000 --> 00:31:08.000
higher load or even lower load to ensure
that you're able to provide the proper
level of service to your internal or

259
00:31:08.000 --> 00:31:14.000
external cuffs
murs and also be able to control costs
you want to be able to just naturally

260
00:31:14.000 --> 00:31:20.000
grow over time maybe you you want to
launch a database to support an
application that you're having in beta

261
00:31:20.000 --> 00:31:27.000
and then you gradually roll it out to
more users whether it be internal or
external that's going to naturally drive

262
00:31:27.000 --> 00:31:31.000
more usage on your database and you're
going to want to grow it up but maybe
you don't want to provision and pay for

263
00:31:31.000 --> 00:31:40.000
the largest database you think you'll
need right at the very start and then
another note on controlling costs you

264
00:31:40.000 --> 00:31:46.000
know all of this has kind of a
supporting your users and controlling
costs aspect to it but what if you could

265
00:31:46.000 --> 00:31:54.000
actually have the ability to if you have
a database let's say it's very heavily
used Monday through Friday and on the

266
00:31:54.000 --> 00:32:01.000
weekends it's hardly ever used at all
it's way over provision for the weekends
another interesting idea around

267
00:32:01.000 --> 00:32:07.000
controlling costs when it comes to
scaling is what if I could actually take
my database and scale it down friday

268
00:32:07.000 --> 00:32:12.000
night to a minimum size that's
appropriate for the weekend so the
database is still up and it can be

269
00:32:12.000 --> 00:32:18.000
accessed if needed but not I'm going to
pay for this this way of a provision
database during the weekend and then I

270
00:32:18.000 --> 00:32:24.000
could scale it up monday morning before
everybody comes in and how the database
happen up and running it at the size

271
00:32:24.000 --> 00:32:31.000
that's necessary for the for the weekday
and I've been able to kind of use the
scaling process to actually help control

272
00:32:31.000 --> 00:32:40.000
my costs a little bit while still being
able to ride the right level of service
to my end users so when you're on RTS

273
00:32:40.000 --> 00:32:47.000
there's a few different things that you
can scale one is the master database
instance itself you can scale that

274
00:32:47.000 --> 00:32:54.000
vertically you can make it bigger or
smaller changing the the amount of CPU a
memory that you're using for that

275
00:32:54.000 --> 00:33:00.000
database you can also scale your read
replicas you can once again scale them
vertically to get them bigger or smaller

276
00:33:00.000 --> 00:33:08.000
but you can also do some horizontal
scaling with your read replicas you can
actually add more read replicas to your

277
00:33:08.000 --> 00:33:16.000
Tuukka to work with your master database
if you need to if you're getting a lot
of demand on your read replicas you can

278
00:33:16.000 --> 00:33:23.000
also do some scaling with the storage
that's provided on RT yes no the thing
to keep in mind this is not there's not

279
00:33:23.000 --> 00:33:28.000
much flexibility that comes with the
storage scaling as you might see with
the reed replicas of the database

280
00:33:28.000 --> 00:33:35.000
instance and it takes time you can
actually provision a certain amount of
storage on RDS for all the non turbo

281
00:33:35.000 --> 00:33:42.000
engines and then watch that and you can
can you can scale and add more storage
over time to your database so you're

282
00:33:42.000 --> 00:33:48.000
only paying for what you need as you
need it but that process can take up to
24 hours for the RDS service to actually

283
00:33:48.000 --> 00:33:54.000
get the new amount of storage
provisioned and you may see a little bit
of performance impact on your database

284
00:33:54.000 --> 00:34:01.000
of all that's happening you could also
scale up and down the I ops that you
have provisioned to your database if

285
00:34:01.000 --> 00:34:06.000
you're using provisioned I ops storage
but once again that requires a little
thought and planning around when you'd

286
00:34:06.000 --> 00:34:13.000
want to do it and it takes time for RDS
service to actually implement that and
get it to the levels that you need so it

287
00:34:13.000 --> 00:34:18.000
can be done but you need to have a
little bit more planning in patience
when it comes to scaling around the

288
00:34:18.000 --> 00:34:26.000
storage Katie mentioned a few minutes
ago about the the reed replicas that
Aurora offers and in the last couple

289
00:34:26.000 --> 00:34:32.000
months Aurora's offered is going to
released a very cool feature called read
replica endpoints so prior to this with

290
00:34:32.000 --> 00:34:39.000
each read replica that you created in
Aurora you would have a separate
endpoint for all of those read replicas

291
00:34:39.000 --> 00:34:46.000
so if you had 15 read replicas as part
of your cluster you could have 15
different endpoints that you need to

292
00:34:46.000 --> 00:34:51.000
manage and make sure that you're getting
out to the right people and know who has
access to those endpoints so with Reed

293
00:34:51.000 --> 00:34:58.000
replica endpoints with your Aurora
cluster now you get one read-only
endpoint that covers all of your read

294
00:34:58.000 --> 00:35:04.000
replicas so if you have one read replica
you have 15 it's the same endpoint if
you've used you know elastic load

295
00:35:04.000 --> 00:35:12.000
balancing and ec2 it's a very similar
concept so now you have the ability to
scale your read replicas to meet demand

296
00:35:12.000 --> 00:35:20.000
scale them vertically or horizontally
while never having to worry about
dishing out or reclaiming endpoints from

297
00:35:20.000 --> 00:35:30.000
end users or applications who are using
your read replica for your database
scalings got just a few steps that go

298
00:35:30.000 --> 00:35:36.000
with it then we're going to focus on the
master database instance in this case
but this is some screenshots from the

299
00:35:36.000 --> 00:35:41.000
man
console you're going to make a scaling a
sizing change to your database go to the

300
00:35:41.000 --> 00:35:49.000
instance actions options choose the
modify option choose the new database
instance size that you want and then at

301
00:35:49.000 --> 00:35:58.000
the very bottom of the screen there's
this apply immediately check box if you
don't check that the RDS service will do

302
00:35:58.000 --> 00:36:03.000
the modification but it will do it
during your scheduled maintenance window
that you've defined for your RDS

303
00:36:03.000 --> 00:36:12.000
instance I've missed this before and
I've SAT there watching waiting for just
wish to modify and it never does if you

304
00:36:12.000 --> 00:36:18.000
want that change to happen right away
make sure you're checking that apply
immediately option and the RDS service

305
00:36:18.000 --> 00:36:27.000
will start the modifications as soon as
you commit this commit this change so we
talked about scaling let's walk through

306
00:36:27.000 --> 00:36:34.000
what happens when you're running a
single availability zone or a multi
availability zone configuration so if

307
00:36:34.000 --> 00:36:39.000
you're running a single availability
zone and you decide that you want to
resize your master database instance

308
00:36:39.000 --> 00:36:46.000
you've done all the work you've checked
apply immediately the RDS service is
actually going to take the existing

309
00:36:46.000 --> 00:36:56.000
database out of service and then resize
it and during that period of time you
will not be able to use the DNS endpoint

310
00:36:56.000 --> 00:37:01.000
that comes with your RDS instance to be
able to connect to your master database
it will not be accessible again until

311
00:37:01.000 --> 00:37:07.000
the RDS service has completed resizing
your database and bringing it back
online this is a screenshot of an

312
00:37:07.000 --> 00:37:13.000
example of the events that the RDS
service sends during that period of time
you can see there's about a three to six

313
00:37:13.000 --> 00:37:19.000
minute window where my database was it
was unavailable and inaccessible to me
during that scaling operation so that

314
00:37:19.000 --> 00:37:25.000
may be acceptable depending on your
situation but if you've got something
that needs to to be available a little

315
00:37:25.000 --> 00:37:31.000
bit more that may not be suitable for
you if you're running in the multi
availability zone configurations and

316
00:37:31.000 --> 00:37:39.000
some cool stuff happens when you decide
to resize your database instance the RDS
service is first going to actually go

317
00:37:39.000 --> 00:37:44.000
work on that standby database it's not
going to touch the master database yet
so you're at this point still able to

318
00:37:44.000 --> 00:37:50.000
receive connections and people can
access your database it will resize that
standby database

319
00:37:50.000 --> 00:37:58.000
and it will then flip that standby
database to be your master database and
it will repoint the DNS records to point

320
00:37:58.000 --> 00:38:08.000
to your new resized master database and
at that point it will then resize what
was the master database to match the the

321
00:38:08.000 --> 00:38:13.000
size that you've chosen and turn that
master database into the standby
database so you're still running in a

322
00:38:13.000 --> 00:38:20.000
multi AZ configuration and you're sized
at the level that you need to be for
both your master and your standby these

323
00:38:20.000 --> 00:38:28.000
are the events that RDS records and
sends when you're scaling or resizing a
multi AZ database and you can see here

324
00:38:28.000 --> 00:38:35.000
that it's been doing a bunch of work
before it even actually goes and does
the multi AZ failover so in total with

325
00:38:35.000 --> 00:38:42.000
with just this DNS failover you've got
about a 30 to 60 second window where
your dns entries may be cached before

326
00:38:42.000 --> 00:38:48.000
they they recycle see your applications
are going to be a little bit tolerant
you no need to either fail gracefully or

327
00:38:48.000 --> 00:38:58.000
retry those transactions during that
short window when your DNS failover is
happening so now that we've figured out

328
00:38:58.000 --> 00:39:04.000
okay there are ways that we can scale
different things on RDS we start
thinking about what we can do around

329
00:39:04.000 --> 00:39:12.000
maybe automation for some of that
scaling so the top example here is I
have is just an example of using the the

330
00:39:12.000 --> 00:39:21.000
command-line interface for RDS calling
the modified DB instance command action
I'm setting the DB instance class to

331
00:39:21.000 --> 00:39:28.000
what I want it to be and I'm setting the
apply immediately option as a parameter
into that command line call if you

332
00:39:28.000 --> 00:39:36.000
remember back to my example a few slides
ago when I talked about being able to
resize my database based on a schedule

333
00:39:36.000 --> 00:39:41.000
based on usage patterns that I'm seeing
where I'm very heavily used on the
weekends or weekdays and hardly use it

334
00:39:41.000 --> 00:39:47.000
all on the weekends we could actually
now start looking at taking that you
know that CLI example or if you use the

335
00:39:47.000 --> 00:39:55.000
SDK that's fine as well in my example I
put those into two different scripts the
scripts are the same the only thing

336
00:39:55.000 --> 00:40:00.000
that's the only thing that's different
between the two scripts is that the size
of the database instance so I've got a

337
00:40:00.000 --> 00:40:04.000
simple cron job that runs at eight
o'clock on Friday to call a script to
scale down

338
00:40:04.000 --> 00:40:09.000
RDS instance and I've got a script that
run another cron job that runs at four
o'clock in the morning on monday to

339
00:40:09.000 --> 00:40:16.000
scale my RDS instance back up to the
sides that's needed to support my
weekday operations and now I have some

340
00:40:16.000 --> 00:40:22.000
automated scaling happen around my
database to allow me to be able to
control costs in more of a hands-off way

341
00:40:22.000 --> 00:40:33.000
even take that a step further for
scheduling using AWS lambda which is our
event-driven service lambda gives you

342
00:40:33.000 --> 00:40:38.000
the ability to actually schedule your
lambda functions so that they've run you
know very similar to cron at a

343
00:40:38.000 --> 00:40:44.000
particular period of time so in this
example I've written some small Python
code to once again call the modified EV

344
00:40:44.000 --> 00:40:52.000
instance API give it a specific instance
that I want to change which size I want
it to be and set the apply immediately

345
00:40:52.000 --> 00:40:59.000
again and then I scheduled that need of
us lambda to run at eight o'clock on
friday and four a.m. on monday two

346
00:40:59.000 --> 00:41:04.000
different basically the same script the
only thing that changes is that is the
size of the DB instance and I now don't

347
00:41:04.000 --> 00:41:13.000
even need a server to support running
cron to be able to have my automated
scaling happen going even further than

348
00:41:13.000 --> 00:41:20.000
then scheduling my scaling I can
actually now start looking at using
metrics that RDS makes available to me

349
00:41:20.000 --> 00:41:29.000
to do some more metric space scaling so
as Katie mentioned earlier RDS sends
many metrics into cloud watch you can

350
00:41:29.000 --> 00:41:35.000
create alarms and cloud watch based on
thresholds this when those alarms are
breached you can send the notification

351
00:41:35.000 --> 00:41:44.000
about that alarm to the AWS simple
notification service to a particular
topic and then you know that topic you

352
00:41:44.000 --> 00:41:49.000
can subscribe various things I can have
it send an email I can have it call an
HTTPS service but you can also subscribe

353
00:41:49.000 --> 00:41:58.000
a lambda function to an SNS topic and
what that gives me the ability to do now
is actually be able to take action based

354
00:41:58.000 --> 00:42:05.000
on the alerts that are coming off of my
metrics for the RDS service so this is
another example this extension of the

355
00:42:05.000 --> 00:42:13.000
Python code I showed you earlier this
has been set up to actually pull the
information out of an SNS notification

356
00:42:13.000 --> 00:42:19.000
that's coming from Cloud watch pull out
the name of the database instance
and then modify that database instance

357
00:42:19.000 --> 00:42:25.000
to a different size now this is a very
simple example if you were using this
for production you obviously add in the

358
00:42:25.000 --> 00:42:31.000
things that matter to you and you might
also do some stuff around figuring out
what's the current database instance

359
00:42:31.000 --> 00:42:37.000
size and then choosing to step it up one
if you're resizing or maybe putting a
block that says I'm not going to resize

360
00:42:37.000 --> 00:42:44.000
past this so that we can actually maybe
dig a bit deeper and this is you know
we've been talking about the database

361
00:42:44.000 --> 00:42:51.000
master instance but this same approach
can be applied to storage layer based on
the metrics you're getting off of the

362
00:42:51.000 --> 00:42:57.000
storage layer or to your read replicas
based on the metrics you getting on your
read replicas you can use all of this to

363
00:42:57.000 --> 00:43:02.000
be able to do vertical scaling or
horizontal scaling for your read
replicas as well so a lot of cool things

364
00:43:02.000 --> 00:43:11.000
that exist when it comes to building
more automation when it around scaling
of your RDS instances and with that I

365
00:43:11.000 --> 00:43:30.000
will hand it back over to Katie
I think it's gone
ability to take reliable backups to deal

366
00:43:30.000 --> 00:43:35.000
with issues like data corruption
disaster recovery and to create other
database instances and is an important

367
00:43:35.000 --> 00:43:42.000
part of running and managing any
database so let's dive deeper into this
topic let's start with automated backups

368
00:43:42.000 --> 00:43:51.000
automated backups are scheduled one time
a day and you can these are managed by
the RDS service itself you can specify

369
00:43:51.000 --> 00:43:58.000
the preferred backup window and during
that prefer black of window the whole
RDS instance the whole instance is

370
00:43:58.000 --> 00:44:08.000
backed up these are by default the
retention period for a automated backup
is one day but you can configure it to

371
00:44:08.000 --> 00:44:18.000
be up to 35 days to meet your needs the
way it's done in in my sequel postgres
Maria Oracle and sequel server is

372
00:44:18.000 --> 00:44:26.000
different than how it's done in Aurora
for as I was mentioning earlier laura is
designed differently you don't have to

373
00:44:26.000 --> 00:44:33.000
schedule backups there is no preferred
backup window at all backups in your
aura are automatic they are continuous

374
00:44:33.000 --> 00:44:42.000
and they are incremental and they are in
s3 so it's much more easy to deal with
backups in Aurora let's look at what

375
00:44:42.000 --> 00:44:49.000
steps are followed when automated
backups happen now this is for all the
engines except Iran so every day during

376
00:44:49.000 --> 00:44:57.000
your backup window the storage volume in
your RDS instance is backed up and if
you are using a multi easy configuration

377
00:44:57.000 --> 00:45:06.000
the backup is taken from the standby
instance so that the performance is not
impacted along with the storage instance

378
00:45:06.000 --> 00:45:15.000
to restore your database you also need
the transaction log so five minutes of
transaction logs are also backed up the

379
00:45:15.000 --> 00:45:23.000
storage volume back up time along with
the transaction log time give you the
latest restorable time for your for your

380
00:45:23.000 --> 00:45:34.000
RDS instance and you have the ability to
restore your database to any second you
choose within that restorable time show

381
00:45:34.000 --> 00:45:40.000
of hands how many of you have had to
restore a database
I see someone lucky people here how many

382
00:45:40.000 --> 00:45:49.000
of you found it to be a pleasant
experience oh wow we have some great
people also well it's not fun and but

383
00:45:49.000 --> 00:45:58.000
RDS makes it much more convenient for
you to restore from your backups you
just have to point it to the rest from

384
00:45:58.000 --> 00:46:05.000
within the latest restorable period you
pointed to the last point in time where
you want to restore to and restoring

385
00:46:05.000 --> 00:46:13.000
your RDS instances similar to creating a
new instance in the sense that you have
to do some of the same configuration

386
00:46:13.000 --> 00:46:21.000
like you would do if you were launching
a new instance an important best
practice from from this particular

387
00:46:21.000 --> 00:46:27.000
feature is that you can actually restore
to a smaller instance which is very
useful if you are just testing your

388
00:46:27.000 --> 00:46:34.000
backups we should all test our backups
as we have seen earlier in the year some
bad things happen when the dr strategy

389
00:46:34.000 --> 00:46:41.000
is not tested even if within big company
so when you are just restoring for
testing purposes use a smaller instance

390
00:46:41.000 --> 00:46:49.000
when you are restoring from a backup
just to give that RDS instance to a dev
team for for working with it you can

391
00:46:49.000 --> 00:46:56.000
restore to a smaller instance but if you
are restoring to replace your production
database instance then you will probably

392
00:46:56.000 --> 00:47:04.000
restore to a similar size and similar
configuration like your primary database
instance that you have another option

393
00:47:04.000 --> 00:47:14.000
for you is to use snapshots snapshots
are manual in nature you can take
snapshots at any given time and they are

394
00:47:14.000 --> 00:47:22.000
backed up to s3 you can also restore
from snapshots and create new instances
as well one of the key features here is

395
00:47:22.000 --> 00:47:29.000
that you have more flexibility into how
much of the duration of retention the
retention period is not limited to 35

396
00:47:29.000 --> 00:47:38.000
days and you can keep them beyond 35
days as well and the last topic I want
to talk about is migrating to a double

397
00:47:38.000 --> 00:47:46.000
yes there are several tools and services
that AWS provides AWS partners provide
and then there are

398
00:47:46.000 --> 00:47:53.000
cool tools in the open source community
as well that make it easy for you to
migrate to RDS I will give you a couple

399
00:47:53.000 --> 00:48:00.000
of examples and talk about two of the
services amazon offers the first example
i want to talk about is migrating from

400
00:48:00.000 --> 00:48:11.000
my sequel which is running on ram in
this case and migrating from that into a
target amazon aurora rd amazon instance

401
00:48:11.000 --> 00:48:20.000
within the RDS family in this case you
can use my sequel dump this is my sequel
we are talking about so the utilities

402
00:48:20.000 --> 00:48:28.000
work RDS is no different and use the my
sequel dump facility to dump and then
import the data in but some studies

403
00:48:28.000 --> 00:48:35.000
claim that if you use percona extra
backer which which is a free open source
tool they found it to be 20 times faster

404
00:48:35.000 --> 00:48:42.000
it's hot backup of your data base there
is compression built in and it's
incremental so if you use the pre kuna

405
00:48:42.000 --> 00:48:51.000
extra backup tool to create a backup
file of your database you can then bring
that file over the wire into s3 you can

406
00:48:51.000 --> 00:48:58.000
speed that transfer up by using the
transfer acceleration feature within s3
and you can also use multi-part uploads

407
00:48:58.000 --> 00:49:05.000
which will junk up your file and try to
upload those parts in parallel and then
steal them back then stitch them back in

408
00:49:05.000 --> 00:49:12.000
with in s3 that's also helpful if we
have the file which is more than five
terabytes in size because that's the

409
00:49:12.000 --> 00:49:20.000
object size in s3 but if you have if
you're dealing with large backup files
say several terabytes then you can also

410
00:49:20.000 --> 00:49:28.000
consider the AWS import/export snowball
appliance you put your data in snowball
ship it to us we'll bring the data into

411
00:49:28.000 --> 00:49:39.000
s3 now once the data is in s3 creating a
Aurora cluster from it is just a click
away you point it to the s3 bucket where

412
00:49:39.000 --> 00:49:47.000
the data is sitting and Iraq luster is
generated from them so it makes the
migration path quite easy the other

413
00:49:47.000 --> 00:49:57.000
example I want to talk about is sequel
server database migration into RDS and
in this case we are going to use the

414
00:49:57.000 --> 00:50:02.000
native
backup restore functionality within
sequel server that functionality give

415
00:50:02.000 --> 00:50:11.000
you gives u dot back files you again
bring those dot back files into s3 using
snowball or using multi-part upload

416
00:50:11.000 --> 00:50:20.000
transfer acceleration the whole thing
and once it is in s3 from the command
prompt you can just bring that data into

417
00:50:20.000 --> 00:50:27.000
sequel server a cool thing here if you
notice is that the arrows are
bi-directional so you can use this

418
00:50:27.000 --> 00:50:39.000
method to migrate data into or out of
the clock AWS database migration service
was announced a train went last year

419
00:50:39.000 --> 00:50:49.000
made GA March of this year and since
that time it has done more than 14,000
different database migrations one of the

420
00:50:49.000 --> 00:50:56.000
cool features of this migration services
that it supports heterogeneous targets
for example you can migrate from Oracle

421
00:50:56.000 --> 00:51:05.000
to postgres sequel engine of RDS or you
can have homogeneous is equal to my
sequel as well when you set up database

422
00:51:05.000 --> 00:51:12.000
migration service it's going to you
point to your source database to your
target database and it does the work of

423
00:51:12.000 --> 00:51:18.000
migration for you and after that
migration is done it keeps the two
databases in sync so that you can choose

424
00:51:18.000 --> 00:51:28.000
the appropriate cut over time to move
over to your target database when we are
dealing with heterogeneous migrations

425
00:51:28.000 --> 00:51:37.000
such that your database engine in the
source is different than database engine
at the target the database objects do

426
00:51:37.000 --> 00:51:47.000
not translate directly I'm talking about
stored procedures schemas tables indexes
DML constructs etcetera they need to be

427
00:51:47.000 --> 00:51:55.000
converted from one generation to another
AWS schema conversion tool is helps with
that let's say it's a development

428
00:51:55.000 --> 00:52:01.000
environment you download it to your
desktop and it you point it to the
schema and it's going to help you

429
00:52:01.000 --> 00:52:07.000
convert it to the target schema it's not
going to be hundred percent successful
all the time but for the portions in the

430
00:52:07.000 --> 00:52:12.000
schema is not able to convert it's going
to highlight them
and it's going to give you suggestions

431
00:52:12.000 --> 00:52:22.000
on how you might migrate it so it helps
you reduce the overall time it takes to
do your migrations of God so with that I

432
00:52:22.000 --> 00:.000
would like to thank you for your time
and Scott and I would be happy to answer
any questions you might have